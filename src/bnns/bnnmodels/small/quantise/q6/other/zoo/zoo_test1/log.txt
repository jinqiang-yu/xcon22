2022-01-29 12:53:51 - INFO - saving to ./results/small/quantise/q6/other/zoo/zoo_test1/
2022-01-29 12:53:51 - DEBUG - run arguments: Namespace(config='./configs/config_small.json', data='../../paper_bench/complete/quantise/q6/other/zoo/zoo_data.csv', encode=None, id=0, load=None, neighprec=-1, results='./results/small/quantise/q6/other/zoo/zoo_test1/', test='../../paper_bench/cv/test/quantise/q6/other/zoo/zoo_test1_data.csv', train='../../paper_bench/cv/train/quantise/q6/other/zoo/zoo_train1_data.csv')
2022-01-29 12:53:51 - INFO - creating model mlp_binary
2022-01-29 12:53:51 - INFO - created model with configuration: {'name': 'mlp_binary', 'type': 'cpu', 'type_model': 'torch.FloatTensor', 'layers': [10, 5, 5, 7]}
2022-01-29 12:53:51 - INFO - number of parameters: 537
2022-01-29 12:53:51 - INFO - training regime: {0: {'optimizer': 'Adam', 'lr': 0.025, 'betas': (0.9, 0.999)}, 20: {'lr': 0.0025}, 50: {'lr': 0.00025}, 75: {'lr': 2.5e-05}}
2022-01-29 12:53:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:51 - INFO - TRAINING - Epoch: [0][0/2]	Time 0.255 (0.255)	Data 0.223 (0.223)	Loss 3.3577 (3.3577)	Prec@1 23.438 (23.438)	
2022-01-29 12:53:51 - INFO - EVALUATING - Epoch: [0][0/1]	Time 0.236 (0.236)	Data 0.234 (0.234)	Loss 1.3979 (1.3979)	Prec@1 61.905 (61.905)	
2022-01-29 12:53:51 - INFO - 
 Epoch: 1	Training Loss 3.0793 	Training Prec@1 26.250 	Validation Loss 1.3979 	Validation Prec@1 61.905 	
2022-01-29 12:53:51 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:51 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:52 - INFO - TRAINING - Epoch: [1][0/2]	Time 0.201 (0.201)	Data 0.197 (0.197)	Loss 2.0840 (2.0840)	Prec@1 40.625 (40.625)	
2022-01-29 12:53:52 - INFO - EVALUATING - Epoch: [1][0/1]	Time 0.197 (0.197)	Data 0.196 (0.196)	Loss 1.1210 (1.1210)	Prec@1 23.810 (23.810)	
2022-01-29 12:53:52 - INFO - 
 Epoch: 2	Training Loss 1.8934 	Training Prec@1 37.500 	Validation Loss 1.1210 	Validation Prec@1 23.810 	
2022-01-29 12:53:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:52 - INFO - TRAINING - Epoch: [2][0/2]	Time 0.204 (0.204)	Data 0.201 (0.201)	Loss 1.5501 (1.5501)	Prec@1 23.438 (23.438)	
2022-01-29 12:53:52 - INFO - EVALUATING - Epoch: [2][0/1]	Time 0.209 (0.209)	Data 0.208 (0.208)	Loss 0.6007 (0.6007)	Prec@1 80.952 (80.952)	
2022-01-29 12:53:52 - INFO - 
 Epoch: 3	Training Loss 1.5707 	Training Prec@1 28.750 	Validation Loss 0.6007 	Validation Prec@1 80.952 	
2022-01-29 12:53:52 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:52 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:52 - INFO - TRAINING - Epoch: [3][0/2]	Time 0.201 (0.201)	Data 0.197 (0.197)	Loss 1.3551 (1.3551)	Prec@1 67.188 (67.188)	
2022-01-29 12:53:53 - INFO - EVALUATING - Epoch: [3][0/1]	Time 0.238 (0.238)	Data 0.236 (0.236)	Loss 0.9559 (0.9559)	Prec@1 66.667 (66.667)	
2022-01-29 12:53:53 - INFO - 
 Epoch: 4	Training Loss 1.2915 	Training Prec@1 62.500 	Validation Loss 0.9559 	Validation Prec@1 66.667 	
2022-01-29 12:53:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:53 - INFO - TRAINING - Epoch: [4][0/2]	Time 0.191 (0.191)	Data 0.188 (0.188)	Loss 1.0465 (1.0465)	Prec@1 60.938 (60.938)	
2022-01-29 12:53:53 - INFO - EVALUATING - Epoch: [4][0/1]	Time 0.229 (0.229)	Data 0.227 (0.227)	Loss 0.7062 (0.7062)	Prec@1 80.952 (80.952)	
2022-01-29 12:53:53 - INFO - 
 Epoch: 5	Training Loss 0.9910 	Training Prec@1 66.250 	Validation Loss 0.7062 	Validation Prec@1 80.952 	
2022-01-29 12:53:53 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:53 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:53 - INFO - TRAINING - Epoch: [5][0/2]	Time 0.195 (0.195)	Data 0.192 (0.192)	Loss 1.8906 (1.8906)	Prec@1 59.375 (59.375)	
2022-01-29 12:53:54 - INFO - EVALUATING - Epoch: [5][0/1]	Time 0.233 (0.233)	Data 0.232 (0.232)	Loss 1.0789 (1.0789)	Prec@1 80.952 (80.952)	
2022-01-29 12:53:54 - INFO - 
 Epoch: 6	Training Loss 1.6826 	Training Prec@1 58.750 	Validation Loss 1.0789 	Validation Prec@1 80.952 	
2022-01-29 12:53:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:54 - INFO - TRAINING - Epoch: [6][0/2]	Time 0.190 (0.190)	Data 0.187 (0.187)	Loss 1.3553 (1.3553)	Prec@1 56.250 (56.250)	
2022-01-29 12:53:54 - INFO - EVALUATING - Epoch: [6][0/1]	Time 0.234 (0.234)	Data 0.232 (0.232)	Loss 1.0494 (1.0494)	Prec@1 71.429 (71.429)	
2022-01-29 12:53:54 - INFO - 
 Epoch: 7	Training Loss 1.2372 	Training Prec@1 61.250 	Validation Loss 1.0494 	Validation Prec@1 71.429 	
2022-01-29 12:53:54 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:54 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:54 - INFO - TRAINING - Epoch: [7][0/2]	Time 0.217 (0.217)	Data 0.214 (0.214)	Loss 1.0662 (1.0662)	Prec@1 67.188 (67.188)	
2022-01-29 12:53:55 - INFO - EVALUATING - Epoch: [7][0/1]	Time 0.211 (0.211)	Data 0.209 (0.209)	Loss 0.8130 (0.8130)	Prec@1 76.190 (76.190)	
2022-01-29 12:53:55 - INFO - 
 Epoch: 8	Training Loss 0.9578 	Training Prec@1 71.250 	Validation Loss 0.8130 	Validation Prec@1 76.190 	
2022-01-29 12:53:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:55 - INFO - TRAINING - Epoch: [8][0/2]	Time 0.205 (0.205)	Data 0.202 (0.202)	Loss 1.1739 (1.1739)	Prec@1 73.438 (73.438)	
2022-01-29 12:53:55 - INFO - EVALUATING - Epoch: [8][0/1]	Time 0.205 (0.205)	Data 0.203 (0.203)	Loss 0.5197 (0.5197)	Prec@1 90.476 (90.476)	
2022-01-29 12:53:55 - INFO - 
 Epoch: 9	Training Loss 1.1185 	Training Prec@1 72.500 	Validation Loss 0.5197 	Validation Prec@1 90.476 	
2022-01-29 12:53:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:55 - INFO - TRAINING - Epoch: [9][0/2]	Time 0.222 (0.222)	Data 0.218 (0.218)	Loss 0.8821 (0.8821)	Prec@1 75.000 (75.000)	
2022-01-29 12:53:55 - INFO - EVALUATING - Epoch: [9][0/1]	Time 0.198 (0.198)	Data 0.196 (0.196)	Loss 0.7304 (0.7304)	Prec@1 66.667 (66.667)	
2022-01-29 12:53:55 - INFO - 
 Epoch: 10	Training Loss 0.9471 	Training Prec@1 72.500 	Validation Loss 0.7304 	Validation Prec@1 66.667 	
2022-01-29 12:53:55 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:55 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:56 - INFO - TRAINING - Epoch: [10][0/2]	Time 0.196 (0.196)	Data 0.193 (0.193)	Loss 1.4422 (1.4422)	Prec@1 53.125 (53.125)	
2022-01-29 12:53:56 - INFO - EVALUATING - Epoch: [10][0/1]	Time 0.217 (0.217)	Data 0.215 (0.215)	Loss 0.8864 (0.8864)	Prec@1 66.667 (66.667)	
2022-01-29 12:53:56 - INFO - 
 Epoch: 11	Training Loss 1.5044 	Training Prec@1 48.750 	Validation Loss 0.8864 	Validation Prec@1 66.667 	
2022-01-29 12:53:56 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:56 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:56 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:56 - INFO - TRAINING - Epoch: [11][0/2]	Time 0.243 (0.243)	Data 0.239 (0.239)	Loss 1.3410 (1.3410)	Prec@1 56.250 (56.250)	
2022-01-29 12:53:56 - INFO - EVALUATING - Epoch: [11][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.9017 (0.9017)	Prec@1 71.429 (71.429)	
2022-01-29 12:53:56 - INFO - 
 Epoch: 12	Training Loss 1.2107 	Training Prec@1 62.500 	Validation Loss 0.9017 	Validation Prec@1 71.429 	
2022-01-29 12:53:56 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:56 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:56 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:57 - INFO - TRAINING - Epoch: [12][0/2]	Time 0.191 (0.191)	Data 0.188 (0.188)	Loss 1.4040 (1.4040)	Prec@1 75.000 (75.000)	
2022-01-29 12:53:57 - INFO - EVALUATING - Epoch: [12][0/1]	Time 0.238 (0.238)	Data 0.237 (0.237)	Loss 0.6947 (0.6947)	Prec@1 85.714 (85.714)	
2022-01-29 12:53:57 - INFO - 
 Epoch: 13	Training Loss 1.3626 	Training Prec@1 72.500 	Validation Loss 0.6947 	Validation Prec@1 85.714 	
2022-01-29 12:53:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:57 - INFO - TRAINING - Epoch: [13][0/2]	Time 0.191 (0.191)	Data 0.188 (0.188)	Loss 0.8857 (0.8857)	Prec@1 65.625 (65.625)	
2022-01-29 12:53:57 - INFO - EVALUATING - Epoch: [13][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.6331 (0.6331)	Prec@1 80.952 (80.952)	
2022-01-29 12:53:57 - INFO - 
 Epoch: 14	Training Loss 0.9083 	Training Prec@1 68.750 	Validation Loss 0.6331 	Validation Prec@1 80.952 	
2022-01-29 12:53:57 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:57 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:57 - INFO - TRAINING - Epoch: [14][0/2]	Time 0.186 (0.186)	Data 0.183 (0.183)	Loss 1.2038 (1.2038)	Prec@1 62.500 (62.500)	
2022-01-29 12:53:58 - INFO - EVALUATING - Epoch: [14][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.4222 (0.4222)	Prec@1 80.952 (80.952)	
2022-01-29 12:53:58 - INFO - 
 Epoch: 15	Training Loss 1.2123 	Training Prec@1 62.500 	Validation Loss 0.4222 	Validation Prec@1 80.952 	
2022-01-29 12:53:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:58 - INFO - TRAINING - Epoch: [15][0/2]	Time 0.196 (0.196)	Data 0.192 (0.192)	Loss 1.5511 (1.5511)	Prec@1 70.312 (70.312)	
2022-01-29 12:53:58 - INFO - EVALUATING - Epoch: [15][0/1]	Time 0.213 (0.213)	Data 0.211 (0.211)	Loss 0.2160 (0.2160)	Prec@1 95.238 (95.238)	
2022-01-29 12:53:58 - INFO - 
 Epoch: 16	Training Loss 1.5265 	Training Prec@1 68.750 	Validation Loss 0.2160 	Validation Prec@1 95.238 	
2022-01-29 12:53:58 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:58 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:58 - INFO - TRAINING - Epoch: [16][0/2]	Time 0.237 (0.237)	Data 0.234 (0.234)	Loss 1.1705 (1.1705)	Prec@1 71.875 (71.875)	
2022-01-29 12:53:59 - INFO - EVALUATING - Epoch: [16][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.4480 (0.4480)	Prec@1 71.429 (71.429)	
2022-01-29 12:53:59 - INFO - 
 Epoch: 17	Training Loss 1.2253 	Training Prec@1 68.750 	Validation Loss 0.4480 	Validation Prec@1 71.429 	
2022-01-29 12:53:59 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:59 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:59 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:59 - INFO - TRAINING - Epoch: [17][0/2]	Time 0.238 (0.238)	Data 0.234 (0.234)	Loss 0.9060 (0.9060)	Prec@1 60.938 (60.938)	
2022-01-29 12:53:59 - INFO - EVALUATING - Epoch: [17][0/1]	Time 0.238 (0.238)	Data 0.236 (0.236)	Loss 0.3922 (0.3922)	Prec@1 90.476 (90.476)	
2022-01-29 12:53:59 - INFO - 
 Epoch: 18	Training Loss 0.9235 	Training Prec@1 60.000 	Validation Loss 0.3922 	Validation Prec@1 90.476 	
2022-01-29 12:53:59 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:53:59 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:53:59 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:53:59 - INFO - TRAINING - Epoch: [18][0/2]	Time 0.201 (0.201)	Data 0.197 (0.197)	Loss 0.8759 (0.8759)	Prec@1 71.875 (71.875)	
2022-01-29 12:54:00 - INFO - EVALUATING - Epoch: [18][0/1]	Time 0.233 (0.233)	Data 0.232 (0.232)	Loss 0.4475 (0.4475)	Prec@1 85.714 (85.714)	
2022-01-29 12:54:00 - INFO - 
 Epoch: 19	Training Loss 0.8326 	Training Prec@1 72.500 	Validation Loss 0.4475 	Validation Prec@1 85.714 	
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:00 - INFO - TRAINING - Epoch: [19][0/2]	Time 0.196 (0.196)	Data 0.193 (0.193)	Loss 0.8337 (0.8337)	Prec@1 71.875 (71.875)	
2022-01-29 12:54:00 - INFO - EVALUATING - Epoch: [19][0/1]	Time 0.230 (0.230)	Data 0.228 (0.228)	Loss 0.5256 (0.5256)	Prec@1 76.190 (76.190)	
2022-01-29 12:54:00 - INFO - 
 Epoch: 20	Training Loss 1.0436 	Training Prec@1 65.000 	Validation Loss 0.5256 	Validation Prec@1 76.190 	
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:00 - INFO - TRAINING - Epoch: [20][0/2]	Time 0.187 (0.187)	Data 0.184 (0.184)	Loss 0.8459 (0.8459)	Prec@1 70.312 (70.312)	
2022-01-29 12:54:00 - INFO - EVALUATING - Epoch: [20][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.7998 (0.7998)	Prec@1 71.429 (71.429)	
2022-01-29 12:54:00 - INFO - 
 Epoch: 21	Training Loss 0.9721 	Training Prec@1 70.000 	Validation Loss 0.7998 	Validation Prec@1 71.429 	
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:00 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:01 - INFO - TRAINING - Epoch: [21][0/2]	Time 0.203 (0.203)	Data 0.199 (0.199)	Loss 0.6822 (0.6822)	Prec@1 79.688 (79.688)	
2022-01-29 12:54:01 - INFO - EVALUATING - Epoch: [21][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.8409 (0.8409)	Prec@1 66.667 (66.667)	
2022-01-29 12:54:01 - INFO - 
 Epoch: 22	Training Loss 0.6349 	Training Prec@1 80.000 	Validation Loss 0.8409 	Validation Prec@1 66.667 	
2022-01-29 12:54:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:01 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:01 - INFO - TRAINING - Epoch: [22][0/2]	Time 0.202 (0.202)	Data 0.199 (0.199)	Loss 0.6936 (0.6936)	Prec@1 78.125 (78.125)	
2022-01-29 12:54:01 - INFO - EVALUATING - Epoch: [22][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.9105 (0.9105)	Prec@1 71.429 (71.429)	
2022-01-29 12:54:01 - INFO - 
 Epoch: 23	Training Loss 0.6532 	Training Prec@1 80.000 	Validation Loss 0.9105 	Validation Prec@1 71.429 	
2022-01-29 12:54:01 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:01 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:01 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:02 - INFO - TRAINING - Epoch: [23][0/2]	Time 0.192 (0.192)	Data 0.188 (0.188)	Loss 0.4895 (0.4895)	Prec@1 81.250 (81.250)	
2022-01-29 12:54:02 - INFO - EVALUATING - Epoch: [23][0/1]	Time 0.234 (0.234)	Data 0.232 (0.232)	Loss 0.2738 (0.2738)	Prec@1 90.476 (90.476)	
2022-01-29 12:54:02 - INFO - 
 Epoch: 24	Training Loss 0.6895 	Training Prec@1 76.250 	Validation Loss 0.2738 	Validation Prec@1 90.476 	
2022-01-29 12:54:02 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:02 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:02 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:02 - INFO - TRAINING - Epoch: [24][0/2]	Time 0.189 (0.189)	Data 0.185 (0.185)	Loss 0.4058 (0.4058)	Prec@1 85.938 (85.938)	
2022-01-29 12:54:02 - INFO - EVALUATING - Epoch: [24][0/1]	Time 0.197 (0.197)	Data 0.196 (0.196)	Loss 0.2301 (0.2301)	Prec@1 90.476 (90.476)	
2022-01-29 12:54:02 - INFO - 
 Epoch: 25	Training Loss 0.6425 	Training Prec@1 80.000 	Validation Loss 0.2301 	Validation Prec@1 90.476 	
2022-01-29 12:54:02 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:02 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:02 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:02 - INFO - TRAINING - Epoch: [25][0/2]	Time 0.192 (0.192)	Data 0.189 (0.189)	Loss 0.6503 (0.6503)	Prec@1 79.688 (79.688)	
2022-01-29 12:54:03 - INFO - EVALUATING - Epoch: [25][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.1946 (0.1946)	Prec@1 90.476 (90.476)	
2022-01-29 12:54:03 - INFO - 
 Epoch: 26	Training Loss 0.6327 	Training Prec@1 81.250 	Validation Loss 0.1946 	Validation Prec@1 90.476 	
2022-01-29 12:54:03 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:03 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:03 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:03 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:03 - INFO - TRAINING - Epoch: [26][0/2]	Time 0.196 (0.196)	Data 0.192 (0.192)	Loss 0.5827 (0.5827)	Prec@1 79.688 (79.688)	
2022-01-29 12:54:03 - INFO - EVALUATING - Epoch: [26][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.0962 (0.0962)	Prec@1 100.000 (100.000)	
2022-01-29 12:54:03 - INFO - 
 Epoch: 27	Training Loss 0.5196 	Training Prec@1 83.750 	Validation Loss 0.0962 	Validation Prec@1 100.000 	
2022-01-29 12:54:03 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:03 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:03 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:03 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:03 - INFO - TRAINING - Epoch: [27][0/2]	Time 0.196 (0.196)	Data 0.193 (0.193)	Loss 0.6204 (0.6204)	Prec@1 81.250 (81.250)	
2022-01-29 12:54:04 - INFO - EVALUATING - Epoch: [27][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.2817 (0.2817)	Prec@1 90.476 (90.476)	
2022-01-29 12:54:04 - INFO - 
 Epoch: 28	Training Loss 0.6281 	Training Prec@1 81.250 	Validation Loss 0.2817 	Validation Prec@1 90.476 	
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:04 - INFO - TRAINING - Epoch: [28][0/2]	Time 0.183 (0.183)	Data 0.179 (0.179)	Loss 0.6617 (0.6617)	Prec@1 76.562 (76.562)	
2022-01-29 12:54:04 - INFO - EVALUATING - Epoch: [28][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.1128 (0.1128)	Prec@1 100.000 (100.000)	
2022-01-29 12:54:04 - INFO - 
 Epoch: 29	Training Loss 0.7024 	Training Prec@1 77.500 	Validation Loss 0.1128 	Validation Prec@1 100.000 	
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:04 - INFO - TRAINING - Epoch: [29][0/2]	Time 0.243 (0.243)	Data 0.239 (0.239)	Loss 0.5338 (0.5338)	Prec@1 84.375 (84.375)	
2022-01-29 12:54:04 - INFO - EVALUATING - Epoch: [29][0/1]	Time 0.197 (0.197)	Data 0.196 (0.196)	Loss 0.2410 (0.2410)	Prec@1 90.476 (90.476)	
2022-01-29 12:54:04 - INFO - 
 Epoch: 30	Training Loss 0.6778 	Training Prec@1 81.250 	Validation Loss 0.2410 	Validation Prec@1 90.476 	
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:04 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:05 - INFO - TRAINING - Epoch: [30][0/2]	Time 0.202 (0.202)	Data 0.198 (0.198)	Loss 0.4780 (0.4780)	Prec@1 79.688 (79.688)	
2022-01-29 12:54:05 - INFO - EVALUATING - Epoch: [30][0/1]	Time 0.201 (0.201)	Data 0.200 (0.200)	Loss 0.2077 (0.2077)	Prec@1 95.238 (95.238)	
2022-01-29 12:54:05 - INFO - 
 Epoch: 31	Training Loss 0.5699 	Training Prec@1 78.750 	Validation Loss 0.2077 	Validation Prec@1 95.238 	
2022-01-29 12:54:05 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:05 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:05 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:05 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:05 - INFO - TRAINING - Epoch: [31][0/2]	Time 0.202 (0.202)	Data 0.198 (0.198)	Loss 0.3748 (0.3748)	Prec@1 84.375 (84.375)	
2022-01-29 12:54:05 - INFO - EVALUATING - Epoch: [31][0/1]	Time 0.238 (0.238)	Data 0.236 (0.236)	Loss 0.1438 (0.1438)	Prec@1 95.238 (95.238)	
2022-01-29 12:54:05 - INFO - 
 Epoch: 32	Training Loss 0.5169 	Training Prec@1 83.750 	Validation Loss 0.1438 	Validation Prec@1 95.238 	
2022-01-29 12:54:05 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:05 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:05 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:05 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:06 - INFO - TRAINING - Epoch: [32][0/2]	Time 0.201 (0.201)	Data 0.198 (0.198)	Loss 0.4760 (0.4760)	Prec@1 79.688 (79.688)	
2022-01-29 12:54:06 - INFO - EVALUATING - Epoch: [32][0/1]	Time 0.234 (0.234)	Data 0.232 (0.232)	Loss 0.0983 (0.0983)	Prec@1 95.238 (95.238)	
2022-01-29 12:54:06 - INFO - 
 Epoch: 33	Training Loss 0.5510 	Training Prec@1 77.500 	Validation Loss 0.0983 	Validation Prec@1 95.238 	
2022-01-29 12:54:06 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:06 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:06 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:06 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:06 - INFO - TRAINING - Epoch: [33][0/2]	Time 0.202 (0.202)	Data 0.198 (0.198)	Loss 0.3840 (0.3840)	Prec@1 81.250 (81.250)	
2022-01-29 12:54:06 - INFO - EVALUATING - Epoch: [33][0/1]	Time 0.225 (0.225)	Data 0.224 (0.224)	Loss 0.2391 (0.2391)	Prec@1 90.476 (90.476)	
2022-01-29 12:54:06 - INFO - 
 Epoch: 34	Training Loss 0.5002 	Training Prec@1 80.000 	Validation Loss 0.2391 	Validation Prec@1 90.476 	
2022-01-29 12:54:06 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:06 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:06 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:06 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:07 - INFO - TRAINING - Epoch: [34][0/2]	Time 0.197 (0.197)	Data 0.193 (0.193)	Loss 0.4151 (0.4151)	Prec@1 87.500 (87.500)	
2022-01-29 12:54:07 - INFO - EVALUATING - Epoch: [34][0/1]	Time 0.196 (0.196)	Data 0.195 (0.195)	Loss 0.1395 (0.1395)	Prec@1 95.238 (95.238)	
2022-01-29 12:54:07 - INFO - 
 Epoch: 35	Training Loss 0.5706 	Training Prec@1 83.750 	Validation Loss 0.1395 	Validation Prec@1 95.238 	
2022-01-29 12:54:07 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:07 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:07 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:07 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:07 - INFO - TRAINING - Epoch: [35][0/2]	Time 0.234 (0.234)	Data 0.231 (0.231)	Loss 0.4997 (0.4997)	Prec@1 81.250 (81.250)	
2022-01-29 12:54:07 - INFO - EVALUATING - Epoch: [35][0/1]	Time 0.197 (0.197)	Data 0.196 (0.196)	Loss 0.1280 (0.1280)	Prec@1 95.238 (95.238)	
2022-01-29 12:54:07 - INFO - 
 Epoch: 36	Training Loss 0.5648 	Training Prec@1 80.000 	Validation Loss 0.1280 	Validation Prec@1 95.238 	
2022-01-29 12:54:07 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:07 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:07 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:07 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:07 - INFO - TRAINING - Epoch: [36][0/2]	Time 0.196 (0.196)	Data 0.193 (0.193)	Loss 0.4079 (0.4079)	Prec@1 81.250 (81.250)	
2022-01-29 12:54:08 - INFO - EVALUATING - Epoch: [36][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.1778 (0.1778)	Prec@1 90.476 (90.476)	
2022-01-29 12:54:08 - INFO - 
 Epoch: 37	Training Loss 0.4942 	Training Prec@1 81.250 	Validation Loss 0.1778 	Validation Prec@1 90.476 	
2022-01-29 12:54:08 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:08 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:08 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:08 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:08 - INFO - TRAINING - Epoch: [37][0/2]	Time 0.235 (0.235)	Data 0.231 (0.231)	Loss 0.4355 (0.4355)	Prec@1 70.312 (70.312)	
2022-01-29 12:54:08 - INFO - EVALUATING - Epoch: [37][0/1]	Time 0.196 (0.196)	Data 0.195 (0.195)	Loss 0.1185 (0.1185)	Prec@1 95.238 (95.238)	
2022-01-29 12:54:08 - INFO - 
 Epoch: 38	Training Loss 0.5196 	Training Prec@1 70.000 	Validation Loss 0.1185 	Validation Prec@1 95.238 	
2022-01-29 12:54:08 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:08 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:08 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:08 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:08 - INFO - TRAINING - Epoch: [38][0/2]	Time 0.191 (0.191)	Data 0.187 (0.187)	Loss 0.4654 (0.4654)	Prec@1 79.688 (79.688)	
2022-01-29 12:54:09 - INFO - EVALUATING - Epoch: [38][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.1493 (0.1493)	Prec@1 95.238 (95.238)	
2022-01-29 12:54:09 - INFO - 
 Epoch: 39	Training Loss 0.4630 	Training Prec@1 78.750 	Validation Loss 0.1493 	Validation Prec@1 95.238 	
2022-01-29 12:54:09 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:09 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:09 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:09 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:09 - INFO - TRAINING - Epoch: [39][0/2]	Time 0.202 (0.202)	Data 0.198 (0.198)	Loss 0.3631 (0.3631)	Prec@1 81.250 (81.250)	
2022-01-29 12:54:09 - INFO - EVALUATING - Epoch: [39][0/1]	Time 0.189 (0.189)	Data 0.187 (0.187)	Loss 0.1533 (0.1533)	Prec@1 90.476 (90.476)	
2022-01-29 12:54:09 - INFO - 
 Epoch: 40	Training Loss 0.4243 	Training Prec@1 81.250 	Validation Loss 0.1533 	Validation Prec@1 90.476 	
2022-01-29 12:54:09 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:09 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:09 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:09 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:09 - INFO - TRAINING - Epoch: [40][0/2]	Time 0.222 (0.222)	Data 0.218 (0.218)	Loss 0.4095 (0.4095)	Prec@1 82.812 (82.812)	
2022-01-29 12:54:10 - INFO - EVALUATING - Epoch: [40][0/1]	Time 0.234 (0.234)	Data 0.233 (0.233)	Loss 0.2035 (0.2035)	Prec@1 95.238 (95.238)	
2022-01-29 12:54:10 - INFO - 
 Epoch: 41	Training Loss 0.4940 	Training Prec@1 80.000 	Validation Loss 0.2035 	Validation Prec@1 95.238 	
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:10 - INFO - TRAINING - Epoch: [41][0/2]	Time 0.196 (0.196)	Data 0.192 (0.192)	Loss 0.5587 (0.5587)	Prec@1 81.250 (81.250)	
2022-01-29 12:54:10 - INFO - EVALUATING - Epoch: [41][0/1]	Time 0.226 (0.226)	Data 0.224 (0.224)	Loss 0.1557 (0.1557)	Prec@1 95.238 (95.238)	
2022-01-29 12:54:10 - INFO - 
 Epoch: 42	Training Loss 0.6127 	Training Prec@1 80.000 	Validation Loss 0.1557 	Validation Prec@1 95.238 	
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:10 - INFO - TRAINING - Epoch: [42][0/2]	Time 0.202 (0.202)	Data 0.198 (0.198)	Loss 0.5200 (0.5200)	Prec@1 79.688 (79.688)	
2022-01-29 12:54:10 - INFO - EVALUATING - Epoch: [42][0/1]	Time 0.197 (0.197)	Data 0.196 (0.196)	Loss 0.1831 (0.1831)	Prec@1 95.238 (95.238)	
2022-01-29 12:54:10 - INFO - 
 Epoch: 43	Training Loss 0.5162 	Training Prec@1 78.750 	Validation Loss 0.1831 	Validation Prec@1 95.238 	
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:10 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:11 - INFO - TRAINING - Epoch: [43][0/2]	Time 0.187 (0.187)	Data 0.184 (0.184)	Loss 0.4912 (0.4912)	Prec@1 84.375 (84.375)	
2022-01-29 12:54:11 - INFO - EVALUATING - Epoch: [43][0/1]	Time 0.205 (0.205)	Data 0.204 (0.204)	Loss 0.2098 (0.2098)	Prec@1 95.238 (95.238)	
2022-01-29 12:54:11 - INFO - 
 Epoch: 44	Training Loss 0.6273 	Training Prec@1 78.750 	Validation Loss 0.2098 	Validation Prec@1 95.238 	
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:11 - INFO - TRAINING - Epoch: [44][0/2]	Time 0.196 (0.196)	Data 0.192 (0.192)	Loss 0.4636 (0.4636)	Prec@1 87.500 (87.500)	
2022-01-29 12:54:11 - INFO - EVALUATING - Epoch: [44][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.1409 (0.1409)	Prec@1 95.238 (95.238)	
2022-01-29 12:54:11 - INFO - 
 Epoch: 45	Training Loss 0.5403 	Training Prec@1 85.000 	Validation Loss 0.1409 	Validation Prec@1 95.238 	
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:11 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:12 - INFO - TRAINING - Epoch: [45][0/2]	Time 0.202 (0.202)	Data 0.198 (0.198)	Loss 0.5956 (0.5956)	Prec@1 78.125 (78.125)	
2022-01-29 12:54:12 - INFO - EVALUATING - Epoch: [45][0/1]	Time 0.192 (0.192)	Data 0.191 (0.191)	Loss 0.4302 (0.4302)	Prec@1 80.952 (80.952)	
2022-01-29 12:54:12 - INFO - 
 Epoch: 46	Training Loss 0.7549 	Training Prec@1 73.750 	Validation Loss 0.4302 	Validation Prec@1 80.952 	
2022-01-29 12:54:12 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:12 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:12 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:12 - INFO - TRAINING - Epoch: [46][0/2]	Time 0.207 (0.207)	Data 0.203 (0.203)	Loss 0.7576 (0.7576)	Prec@1 68.750 (68.750)	
2022-01-29 12:54:12 - INFO - EVALUATING - Epoch: [46][0/1]	Time 0.197 (0.197)	Data 0.195 (0.195)	Loss 0.3217 (0.3217)	Prec@1 85.714 (85.714)	
2022-01-29 12:54:12 - INFO - 
 Epoch: 47	Training Loss 0.8991 	Training Prec@1 66.250 	Validation Loss 0.3217 	Validation Prec@1 85.714 	
2022-01-29 12:54:12 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:12 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:12 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:12 - INFO - TRAINING - Epoch: [47][0/2]	Time 0.197 (0.197)	Data 0.194 (0.194)	Loss 0.6140 (0.6140)	Prec@1 81.250 (81.250)	
2022-01-29 12:54:13 - INFO - EVALUATING - Epoch: [47][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.2672 (0.2672)	Prec@1 95.238 (95.238)	
2022-01-29 12:54:13 - INFO - 
 Epoch: 48	Training Loss 0.5985 	Training Prec@1 78.750 	Validation Loss 0.2672 	Validation Prec@1 95.238 	
2022-01-29 12:54:13 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:13 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:13 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:13 - INFO - TRAINING - Epoch: [48][0/2]	Time 0.193 (0.193)	Data 0.189 (0.189)	Loss 0.5883 (0.5883)	Prec@1 81.250 (81.250)	
2022-01-29 12:54:13 - INFO - EVALUATING - Epoch: [48][0/1]	Time 0.193 (0.193)	Data 0.191 (0.191)	Loss 0.1503 (0.1503)	Prec@1 95.238 (95.238)	
2022-01-29 12:54:13 - INFO - 
 Epoch: 49	Training Loss 0.5677 	Training Prec@1 80.000 	Validation Loss 0.1503 	Validation Prec@1 95.238 	
2022-01-29 12:54:13 - DEBUG - OPTIMIZER - setting method = Adam
2022-01-29 12:54:13 - DEBUG - OPTIMIZER - setting lr = 0.025
2022-01-29 12:54:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2022-01-29 12:54:13 - DEBUG - OPTIMIZER - setting lr = 0.0025
2022-01-29 12:54:13 - INFO - TRAINING - Epoch: [49][0/2]	Time 0.201 (0.201)	Data 0.198 (0.198)	Loss 0.4525 (0.4525)	Prec@1 78.125 (78.125)	
2022-01-29 12:54:14 - INFO - EVALUATING - Epoch: [49][0/1]	Time 0.198 (0.198)	Data 0.197 (0.197)	Loss 0.3647 (0.3647)	Prec@1 90.476 (90.476)	
2022-01-29 12:54:14 - INFO - 
 Epoch: 50	Training Loss 0.5412 	Training Prec@1 75.000 	Validation Loss 0.3647 	Validation Prec@1 90.476 	
